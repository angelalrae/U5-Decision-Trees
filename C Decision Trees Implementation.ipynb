{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 310](https://github.com/GonzagaCPSC310) Data Mining\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "\n",
    "# Decision Trees Implementation\n",
    "What are our learning objectives for this lesson?\n",
    "* Discuss how decision trees can be represented in Python\n",
    "* Go over some hints for getting started on the implementation\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* Dr. Shawn Bowers' Data Mining notes\n",
    "* [Data Science from Scratch](https://www.amazon.com/Data-Science-Scratch-Principles-Python/dp/149190142X/ref=sr_1_1?ie=UTF8&qid=1491521130&sr=8-1&keywords=joel+grus) by Joel Grus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-up Task(s)\n",
    "\n",
    "|standing |job_status |credit_rating |buys_iphone|\n",
    "|-|-|-|-|\n",
    "|1 |3 |fair |no|\n",
    "|1 |3 |excellent |no|\n",
    "|2 |3 |fair |yes|\n",
    "|2 |2 |fair |yes|\n",
    "|2 |1 |fair |yes|\n",
    "|2 |1 |excellent |no|\n",
    "|2 |1 |excellent |yes|\n",
    "|1 |2 |fair |no|\n",
    "|1 |1 |fair |yes|\n",
    "|2 |2 |fair |yes|\n",
    "|1 |2 |excellent |yes|\n",
    "|2 |2 |excellent |yes|\n",
    "|2 |3 |fair |yes|\n",
    "|2 |2 |excellent |no|\n",
    "|2 |3 |fair |yes|\n",
    "\n",
    "1. Calculate $E_{new}$ for `job_status` for the whole table\n",
    "1. Calculate $E_{new}$ for `credit_rating` for the whole table\n",
    "1. What is the general $E_{new}$ algorithm?\n",
    "1. Open DecisionTreeFun/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing Trees in Python\n",
    "* Can use Python classes\n",
    "* Can use nested lists\n",
    "    * Example (keeping track of the class proportions for each leaf node):\n",
    "```python\n",
    "[\"Attribute\", \"0\",\n",
    "    [\"Value\", \"1\", \n",
    "         [\"Leaves\", [\"yes\",20,20,100%]]\n",
    "    ],\n",
    "    [\"Value\", \"2\",\n",
    "         [\"Attribute\", \"2\",\n",
    "              [\"Value\", \"fair\",\n",
    "                    [\"Leaves\", [\"yes\",4,10,40%], [\"no\",6,10,60%]]\n",
    "              ]\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "```\n",
    "    * Another example:\n",
    "        \n",
    "<img src=\"https://raw.githubusercontent.com/GonzagaCPSC310/U5-Decision-Trees/master/figures/job_candidate_tree.png\" width=\"500\"/>\n",
    "\n",
    "```python\n",
    "[\"Attribute\", \"level\", \n",
    "    [\"Value\", \"Senior\", \n",
    "        [\"Attribute\", \"tweets\", \n",
    "            [\"Value\", \"yes\", \n",
    "                 [\"Leaves\", [\"True\", 2, 5, 40%]]\n",
    "            ],\n",
    "            [\"Value\", \"no\", \n",
    "                 [\"Leaves\", [\"False\", 3, 5, 60%]]\n",
    "            ]\n",
    "        ]\n",
    "    ],\n",
    "    [\"Value\", \"Mid\", [\"Leaves\", \"True\", 4, 4, 100%]],\n",
    "    [\"Value\", \"Junior\", \n",
    "        [\"Attribute\", \"phd\", \n",
    "            [\"Value\", \"yes\", \n",
    "                 [\"Leaves\", [\"False\", 2, 5, 40%]]\n",
    "            ],\n",
    "            [\"Value\", \"no\", \n",
    "                 [\"Leaves\", [\"True\", 3, 5, 60%]\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "```\n",
    "* There are other ways too, these are just a few examples\n",
    "\n",
    "## Main Algorithm\n",
    "`tdidt(instances, att_indexes, att_domains, class_index)`\n",
    "* `instances` is the current partition\n",
    "* `att_indexes` are the indexes of attributes used for classification\n",
    "* `att_domains` the possible values for each attribute (by index)\n",
    "* `class_index` the attribute used as the class label\n",
    "* returns the decision tree\n",
    "    \n",
    "## Helper functions:\n",
    "* `select_attribute(instances, att_indexes, class_index)`\n",
    "    * Returns attribute index to partition on\n",
    "    * Helpful for first step of TDIDT\n",
    "* `partition_instances(instances, att_index, att_domains)`\n",
    "    * Partition list: {att val1:part1, att val2:part2}\n",
    "    * Helpful for second step of TDIDT\n",
    "* `same_class(instances, class_index)`\n",
    "    * True if all instances have same label\n",
    "    * Helpful for base case #1 (all class labels are the same... make a leaf node)\n",
    "* `partition_stats(instances, class_index)`\n",
    "    * Return a list of stats: `[[label1, occ1, tot1], [label2, occ2, tot2], ...]`\n",
    "    * Helpful for base case #2 (no more attributes to partition, need to handle clashes)\n",
    "\n",
    "## Classification\n",
    "* `tdidt_classifier(decision_tree, instance)`\n",
    "    * Takes a decision tree (produced by `tdidt`) and an instance to classify\n",
    "    * Uses the tree to predict the class label for the instance\n",
    "    * Returns the predicted label for the instance"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
